import os
import cv2
import joblib
import numpy as np
import mediapipe as mp
import onnxruntime as ort
from sklearn.svm import SVC
from tools import augmentate
from database import session, Embedding

model_dir = os.path.join(os.path.dirname(__file__), 'models')
rec_path = os.path.join(model_dir, 'quantized_model.onnx')
cls_path = os.path.join(model_dir, 'face_classifier.pkl')
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(
    static_image_mode=False,  # False ƒë·ªÉ s·ª≠ d·ª•ng video (dynamic)
    max_num_faces=1,  # S·ªë l∆∞·ª£ng khu√¥n m·∫∑t t·ªëi ƒëa c√≥ th·ªÉ ph√°t hi·ªán trong m·ªói khung h√¨nh
    refine_landmarks=True,  # L·ªçc landmarks (ƒëi·ªÉm m·ªëc) ƒë·ªÉ c√≥ ƒë·ªô ch√≠nh x√°c cao h∆°n
    min_detection_confidence=0.5,  # M·ª©c ƒë·ªô tin c·∫≠y t·ªëi thi·ªÉu ƒë·ªÉ ph√°t hi·ªán khu√¥n m·∫∑t
)

def load_model():
    #Ki·ªÉm tra s·ª± t·ªìn t·∫°i c·ªßa c√°c th∆∞ m·ª•c c·∫ßn thi·∫øt
    if not os.path.exists('models'):
        os.makedirs('models')

    #Ki·ªÉm tra File ONNX
    rec_model = ort.InferenceSession(rec_path)
    print("Model ONNX s·∫µn s√†ng")

    #Ki·ªÉm tra File SVC
    if not os.path.exists(cls_path):
        print("File SVC ch∆∞a t·ªìn t·∫°i, ƒëang t√°i t·∫°o...")
        cls_model = SVC(kernel='linear', probability=True)
        joblib.dump(cls_model, cls_path)
    cls_model = joblib.load(cls_path)
    print("Model SVC s·∫µn s√†ng")

    return rec_model, cls_model

rec_model, cls_model = load_model()
cls_ready = True
if not hasattr(cls_model, "classes_"):
    cls_ready = False

def detect_face(image):
    """
    Ph√°t hi·ªán khu√¥n m·∫∑t trong ·∫£nh v√† tr√≠ch xu·∫•t v√πng m·∫∑t.
    - Tham s·ªë: ·∫£nh g·ªëc
    - Tr·∫£ v·ªÅ: ·∫£nh khu√¥n m·∫∑t ƒë√£ c·∫Øt v√† t·ªça ƒë·ªô bounding box
    """
    global mp_face_mesh, face_mesh
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    results = face_mesh.process(image_rgb)
    if results.multi_face_landmarks and len(results.multi_face_landmarks) > 0:
        # Khi ph√°t hi·ªán ƒë∆∞·ª£c m·∫∑t, l·∫•y t·ªça ƒë·ªô, chu·∫©n h√≥a t·ªça ƒë·ªô
        face_landmarks = results.multi_face_landmarks[0].landmark
        img_h, img_w, _ = image.shape
        x_coords = [int(landmark.x * img_w) for landmark in face_landmarks]
        y_coords = [int(landmark.y * img_h) for landmark in face_landmarks]

        # X√°c ƒë·ªãnh gi·ªõi h·∫°n bounding box
        x1, x2 = min(x_coords), max(x_coords)
        y1, y2 = min(y_coords), max(y_coords)
        bbox_width, bbox_height = x2 - x1, y2 - y1
        if min(bbox_width, bbox_height) < 50:
            return None, None
        
        bbox = np.array([(x1, y1), (x2, y1), (x2, y2), (x1, y2)], dtype=np.int32)
        x1, y1, x2, y2 = max(0, x1), max(0, y1), min(img_w, x2), min(img_h, y2)
        return image[y1:y2, x1:x2], bbox
    return None, None

def train(saved_face, employee_id):
    """
    Hu·∫•n luy·ªán model v·ªõi t·∫≠p ·∫£nh.
    - Tham s·ªë: danh s√°ch ·∫£nh v√† m√£ nh√¢n vi√™n
    - K·∫øt qu·∫£: tr·∫£ v·ªÅ hu·∫•n luy·ªán th√†nh c√¥ng
    """
    global cls_model, cls_path, rec_model, cls_ready
    cls_ready = True
    images = []

    for buffer in saved_face:
        image_array = np.frombuffer(buffer, np.uint8)
        image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)
        images.append(image)
        
    session.query(Embedding).filter_by(employee_id=employee_id).delete()
    session.commit()
    embeddings, labels = [], []
    # üîπ Load t·∫•t c·∫£ embeddings c≈© t·ª´ database tr∆∞·ªõc khi train
    data = session.query(Embedding).all()
    for item in data:
        embeddings.append(np.frombuffer(item.embedding, dtype=np.float32).tolist())
        labels.append(item.employee_id)

    # üîπ Th√™m embeddings m·ªõi v√†o
    count = 0
    for image in images:
        face, bbox = detect_face(image)
        if face is None: continue

        face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)
        face = cv2.resize(face, (160, 160))
        augmented_faces = augmentate(face)
        all_images = [face] + augmented_faces

        for img in all_images:
            count += 1
            img = img.astype('float32') / 255.0
            img = np.transpose(img, (2, 0, 1))
            img = np.expand_dims(img, axis=0)
            output = rec_model.run(None, {rec_model.get_inputs()[0].name: img})
            embedding = output[0][0].tobytes()

            instance = Embedding(embedding=embedding, employee_id=employee_id)
            session.add(instance)
            session.commit()

            embeddings.append(np.frombuffer(embedding, dtype=np.float32).tolist())
            labels.append(employee_id)
    print('S·ªë l∆∞·ª£ng ·∫£nh: ',count)

    if len(set(labels)) == 1:
        print("Ch·ªâ c√≥ m·ªôt nh√£n duy nh·∫•t, th√™m embedding gi·∫£...")
        dummy_embedding = np.random.rand(len(embeddings[0])).tolist()
        embeddings.append(dummy_embedding)
        labels.append("unknown")

    cls_model = SVC(kernel='linear', probability=True)
    cls_model.fit(embeddings, labels)
    joblib.dump(cls_model, cls_path)
    del images, embeddings, labels
    return {'status': 'Th√†nh c√¥ng', 'classes': cls_model.classes_.tolist()}

def predict(face, threshold=0.8):
    """
    D·ª± ƒëo√°n danh t√≠nh khu√¥n m·∫∑t t·ª´ ·∫£nh.
    - ƒê·∫ßu v√†o: ·∫£nh khu√¥n m·∫∑t ƒë√£ c·∫Øt
    - Tr·∫£ v·ªÅ: employee_id ƒë√°p ·ª©ng ng∆∞·ª°ng
    """
    global cls_model, rec_model, cls_ready
    if not cls_ready: return ''

    # Ti·ªÅn x·ª≠ l√≠ ·∫£nh cho m√¥ h√¨nh Facenet
    img = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (160, 160))
    img = img.astype('float32') / 255.0
    img = np.transpose(img, (2, 0, 1))
    img = np.expand_dims(img, axis=0)
    outputs = rec_model.run(None, {rec_model.get_inputs()[0].name: img})

    # D·ª± ƒëo√°n b·∫±ng SVC, t√≠nh x√°c su·∫•t, ki·ªÉm tra ng∆∞·ª°ng r·ªìi d·ª± ƒëo√°n
    predicted_probs = cls_model.predict_proba(outputs[0])
    confidence, predicted_index = np.max(predicted_probs), np.argmax(predicted_probs, axis=1)[0]
    predicted_label = cls_model.classes_[predicted_index]
    del outputs, predicted_probs, img
    return predicted_label if confidence >= threshold and predicted_label.lower() != "unknown" else ""