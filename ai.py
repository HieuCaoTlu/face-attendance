import os
import cv2
import joblib
import numpy as np
import mediapipe as mp
import onnxruntime as ort
from tools import augmentate
from sklearn.svm import LinearSVC
from database import session, Embedding
from sklearn.calibration import CalibratedClassifierCV

model_dir = os.path.join(os.path.dirname(__file__), 'models')
rec_path = os.path.join(model_dir, 'quantized_model.onnx')
cls_path = os.path.join(model_dir, 'face_classifier.pkl')
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(
    static_image_mode=False,  # False Ä‘á»ƒ sá»­ dá»¥ng video (dynamic)
    max_num_faces=1,  # Sá»‘ lÆ°á»£ng khuÃ´n máº·t tá»‘i Ä‘a cÃ³ thá»ƒ phÃ¡t hiá»‡n trong má»—i khung hÃ¬nh
    refine_landmarks=True,  # Lá»c landmarks (Ä‘iá»ƒm má»‘c) Ä‘á»ƒ cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n
    min_detection_confidence=0.5,  # Má»©c Ä‘á»™ tin cáº­y tá»‘i thiá»ƒu Ä‘á»ƒ phÃ¡t hiá»‡n khuÃ´n máº·t
)

def load_model():
    #Kiá»ƒm tra sá»± tá»“n táº¡i cá»§a cÃ¡c thÆ° má»¥c cáº§n thiáº¿t
    if not os.path.exists('models'):
        os.makedirs('models')

    #Kiá»ƒm tra File ONNX
    rec_model = ort.InferenceSession(rec_path)
    print("Model ONNX sáºµn sÃ ng")

    #Kiá»ƒm tra File SVC
    if not os.path.exists(cls_path):
        cls_model = None
    else:
        cls_model = joblib.load(cls_path)
        print("Model SVC sáºµn sÃ ng")
    return rec_model, cls_model

rec_model, cls_model = load_model()
cls_ready = True
if cls_model == None:
    cls_ready = False

def detect_face(image):
    """
    PhÃ¡t hiá»‡n khuÃ´n máº·t trong áº£nh vÃ  trÃ­ch xuáº¥t vÃ¹ng máº·t.
    - Tham sá»‘: áº£nh gá»‘c
    - Tráº£ vá»: áº£nh khuÃ´n máº·t Ä‘Ã£ cáº¯t vÃ  tá»a Ä‘á»™ bounding box
    """
    global mp_face_mesh, face_mesh
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    results = face_mesh.process(image_rgb)
    if results.multi_face_landmarks and len(results.multi_face_landmarks) > 0:
        face_landmarks = results.multi_face_landmarks[0].landmark
        
        # Láº¥y cÃ¡c Ä‘iá»ƒm landmark cá»§a máº¯t trÃ¡i vÃ  máº¯t pháº£i
        left_eye = [face_landmarks[i] for i in range(33, 133)]  # Landmark cá»§a máº¯t trÃ¡i (index cÃ³ thá»ƒ thay Ä‘á»•i)
        right_eye = [face_landmarks[i] for i in range(362, 463)]  # Landmark cá»§a máº¯t pháº£i (index cÃ³ thá»ƒ thay Ä‘á»•i)
        
        # Kiá»ƒm tra xem cáº£ hai máº¯t cÃ³ Ä‘Æ°á»£c phÃ¡t hiá»‡n khÃ´ng
        if left_eye and right_eye:
            img_h, img_w, _ = image.shape
            # TÃ­nh cÃ¡c Ä‘iá»ƒm bounding box
            x_coords = [int(landmark.x * img_w) for landmark in face_landmarks]
            y_coords = [int(landmark.y * img_h) for landmark in face_landmarks]
            x1, x2 = min(x_coords), max(x_coords)
            y1, y2 = min(y_coords), max(y_coords)
            bbox_width, bbox_height = x2 - x1, y2 - y1
            if min(bbox_width, bbox_height) < 70:
                return None, None
            
            bbox = np.array([(x1, y1), (x2, y1), (x2, y2), (x1, y2)], dtype=np.int32)
            x1, y1, x2, y2 = max(0, x1), max(0, y1), min(img_w, x2), min(img_h, y2)
            return image[y1:y2, x1:x2], bbox

    return None, None

def train(saved_face, employee_id):
    """
    Huáº¥n luyá»‡n model vá»›i táº­p áº£nh.
    - Tham sá»‘: danh sÃ¡ch áº£nh vÃ  mÃ£ nhÃ¢n viÃªn
    - Káº¿t quáº£: tráº£ vá» huáº¥n luyá»‡n thÃ nh cÃ´ng
    """
    global cls_model, cls_path, rec_model, cls_ready, labels
    cls_ready = True
    images = saved_face
        
    session.query(Embedding).filter_by(employee_id=employee_id).delete()
    session.commit()
    embeddings, labels = [], []

    # ðŸ”¹ Load táº¥t cáº£ embeddings cÅ© tá»« database trÆ°á»›c khi train
    data = session.query(Embedding).all()
    for item in data:
        embeddings.append(np.frombuffer(item.embedding, dtype=np.float32).tolist())
        labels.append(item.employee_id)
    
    # ðŸ”¹ ThÃªm embeddings má»›i vÃ o
    count = 0
    instances = []
    for image in images:
        face = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        face = cv2.resize(face, (160, 160))
        augmented_faces = augmentate(face)
        all_images = [face] + augmented_faces

        for img in all_images:
            count += 1
            img = img.astype('float32') / 255.0
            img = np.transpose(img, (2, 0, 1))
            img = np.expand_dims(img, axis=0)
            output = rec_model.run(None, {rec_model.get_inputs()[0].name: img})
            embedding = output[0][0].tobytes()

            instance = Embedding(embedding=embedding, employee_id=employee_id)
            instances.append(instance)

            embeddings.append(np.frombuffer(embedding, dtype=np.float32).tolist())
            labels.append(employee_id)
    
    session.add_all(instances)
    session.commit()
    print('Sá»‘ lÆ°á»£ng áº£nh: ',count)
    previous_labels = len(set(labels))
    if previous_labels < 2:
        dummy_embedding = np.random.rand(len(embeddings[0])).tolist()
        embeddings.append(dummy_embedding)
        embeddings.append(dummy_embedding)
        labels.append("unknown")
        labels.append("unknown")
    cls_model = LinearSVC(random_state=42)
    cls_model = CalibratedClassifierCV(cls_model, cv=2)
    cls_model.fit(embeddings, labels)
    joblib.dump(cls_model, cls_path)
    del images, embeddings, labels
    return {'status': 'ThÃ nh cÃ´ng'}

def refresh_train(employee_id):
    global cls_model, cls_path, rec_model, cls_ready, labels
    cls_ready = True
    session.query(Embedding).filter_by(employee_id=employee_id).delete()
    session.commit()
    embeddings, labels = [], []

    # ðŸ”¹ Load táº¥t cáº£ embeddings cÅ© tá»« database trÆ°á»›c khi train
    data = session.query(Embedding).all()
    for item in data:
        embeddings.append(np.frombuffer(item.embedding, dtype=np.float32).tolist())
        labels.append(item.employee_id)

    previous_labels = len(set(labels))
    if previous_labels < 2:
        dummy_embedding = np.random.rand(len(embeddings[0])).tolist()
        embeddings.append(dummy_embedding)
        embeddings.append(dummy_embedding)
        labels.append("unknown")
        labels.append("unknown")
    cls_model = LinearSVC(random_state=42)
    cls_model = CalibratedClassifierCV(cls_model, cv=2)
    cls_model.fit(embeddings, labels)
    joblib.dump(cls_model, cls_path)
    del images, embeddings, labels
    return {'status': 'ThÃ nh cÃ´ng'}

def predict(face, threshold=0.7):
    """
    Dá»± Ä‘oÃ¡n danh tÃ­nh khuÃ´n máº·t tá»« áº£nh.
    - Äáº§u vÃ o: áº£nh khuÃ´n máº·t Ä‘Ã£ cáº¯t
    - Tráº£ vá»: employee_id Ä‘Ã¡p á»©ng ngÆ°á»¡ng
    """
    global cls_model, rec_model, cls_ready
    if not cls_ready: return ''

    # Tiá»n xá»­ lÃ­ áº£nh cho mÃ´ hÃ¬nh Facenet
    img = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (160, 160))
    img = img.astype('float32') / 255.0
    img = np.transpose(img, (2, 0, 1))
    img = np.expand_dims(img, axis=0)
    outputs = rec_model.run(None, {rec_model.get_inputs()[0].name: img})
    predicted_probs = cls_model.predict_proba(outputs[0])
    confidence = np.max(predicted_probs)
    predicted_index = np.argmax(predicted_probs, axis=1)[0]
    if confidence >= threshold:
        predicted_label = cls_model.classes_[predicted_index]
    else:
        predicted_label = ""
    return predicted_label